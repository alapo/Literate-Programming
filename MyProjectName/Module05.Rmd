---
date: "`r Sys.Date()`"
author: "Dr. Andrew Lapointe"
title: "Module 05"
output: 
  officedown::rdocx_document:
    reference_docx: styles/template.docx          # This is the template that will style my document when its knit
link-citations: yes
linkcolor: red
citecolor: blue
#bibliography: G:/My Drive/ZoteroRPlugin/My Library.bib  # you will need to export your own bibliography
zotero: TRUE
#csl: styles/Citation Styles/spectroscopy-letters.csl    # This sets the style of formatting for references
---

```{r setup, include=FALSE, cache=FALSE, echo=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(apastats,tidyverse, officedown, officer) # Load required packages

knitr::opts_chunk$set(fig.cap = TRUE,
                      fig.path = 'images/',
                      echo = FALSE,
                      warning = FALSE, 
                      message = FALSE,
                      include = TRUE,
                      dpi = 300,
                      crop = TRUE # This will remove the whitespace surrounding an image see here: https://bookdown.org/yihui/rmarkdown-cookbook/crop-plot.html
                      # The following chunks only work with PDF outputs
                      #fig.pos = 'H', # only works with PDFs
                      #fig.align = 'center', # only works with PDFs
                      #out.height="100%",  out.width="100%") # only works with PDFs
)

# Start loading data into the environment
use_betterbiblatex = TRUE

```

# Table of content

<!---BLOCK_TOC--->

\pagebreak

# Part 1

```{r part1a, echo=TRUE}
# Load/Install required packages ---------------------
if (!require("pacman")) install.packages("pacman") # if pacman is not installed, the install it.
pacman::p_load(effectsize, ggpubr, ggstatsplot, googlesheets4, janitor, jtools, knitr, parameters, rio, remotes, report, rstatix, tidyverse,  see, sjPlot, sjmisc) # load/install required packages

# Load your data ----------
df <- read_sheet("https://docs.google.com/spreadsheets/d/1knEo48qeQPtxhzWjgmJf7Sqk7zVAa8NExS6HpXKlNgc", sheet = "1") 

```




```{r part1b, echo=TRUE}
# Summary Statistics 
tbl.desc <- Rmisc::summarySE(data = df %>%
                               gather("Variable", "Value"),
                             measurevar = "Value",
                             groupvars = c("Variable"),
                             conf.interval = 0.95,
                             na.rm = TRUE,
                             .drop = TRUE) %>%
  janitor::clean_names("upper_camel") %>%
  dplyr::rename(
    "Mean" = "Value",
    "CI" = "Ci",
    "SE" = "Se",
    "SD" = "Sd"
  )
```


Summary statistics are shown in Table \@ref(tab:tbl-desc). 

```{r, tab.id="tbl-desc", tab.cap="Descriptive Statistics"}
tbl.desc
```


```{r part1c, echo=TRUE}

# What is the correlation between "x" and "y"
cor(df)

# Run the ANOVA
tbl.anova <- df %>%
  anova_test(x ~ y)

# Run an ANOVA (another way)
model <- aov(y ~ x, data=df) 
summary(model)
```

The ANOVA results are shown in Table \@ref(tab:tbl-anova). 

```{r, tab.id="tbl-anova", tab.cap="ANOVA results"}
tbl.anova
```

Use the code below if you want to get an interpretation of your data

```{r}
aov(y ~ x, data=df) %>%
  report()
```


# Part 2

As I mentioned in the presentation...there are a TON of packages out there to run your statistics. As you start your journey, I would recommend minimizing the number of packages you use until you get comfortable. Here are a few recommendations.

*	[ggstatsplot](https://indrajeetpatil.github.io/ggstatsplot/)
*	[easystats](https://easystats.github.io/easystats/) has several packages to give you inspiration

Let's start by loading all the packages we need and the dataset required for the tutorial. In this example I am using a Google Sheet and the `read_sheet` function. However, for any other data type I would **strongly** recommend using the [`rio` package](https://cran.r-project.org/web/packages/rio/vignettes/rio.html). Which uses "import". I showcase an example below in case you wish to try this with your own data at a later time.


```{r, eval=FALSE, echo=TRUE}
# import an xlsx file
df <- rio::import("raw/data.xlsx", which = "Sheet1") # Uses the `rio` package

# import a csv file
df <- rio::import("raw/data.csv") # Import using `rio`

# import .sav file (SPSS)
df <- rio::import("data/data.sav") 
```


```{r load, echo=TRUE}
# Load/Install required packages ---------------------
# Completed in part 1

# Load your data ----------
df <- read_sheet("https://docs.google.com/spreadsheets/d/1knEo48qeQPtxhzWjgmJf7Sqk7zVAa8NExS6HpXKlNgc", sheet = "anova_data")  # requires 'googlesheets4' library

df$Group <- factor(df$Group, levels=c("Control", "OI", "TBI"), ordered=TRUE) # Data is imported type "character" we need to change that to factors before running statistics.
levels(df$Group) # Confirm that our data is ordered properly.
df$ID <- as.factor(df$ID)
```

Now that you have loaded your data we can proceed to the first step. Getting summary statistics and plotting our data. These are shown in Table \@ref(tab:summary-stats).

```{r tab.id="summary-stats", tab.cap="Mean and standard deviation of our data", include=TRUE, cache=FALSE, echo=TRUE}
df %>%
  group_by(Group) %>%
  get_summary_stats(Score, type = "mean_sd")

```

Now we are going to get a quick boxplot shown . What is your first interpretation of the data using this boxplot alone?

```{r fig.id="boxplot1", fig.caption="Initial boxplot of your data", include=TRUE, cache=FALSE, echo=TRUE}

ggboxplot(df, x = "Group", y = "Score")

```

\pagebreak

## Assumptions

Now we can start checking assumptions. There are four general assumptions when running an ANOVA. These extend to most parametric statistics.

The ANOVA test makes the following assumptions about the data:

1.  ***No significant outliers*** in any cell of the design
2.  ***Normality.*** the data for each design cell should be approximately normally distributed.
3.  ***Homogeneity of variances.*** The variance of the outcome variable should be equal in every cell of the design.
4.  ***Independence of the observations.*** Each subject should belong to only one group. There is no relationship between the observations in each group. Having repeated measures for the same participants is not allowed.

### Assumption \#1: Outliers

```{r ass1, include=TRUE, cache=FALSE, echo=TRUE}
df %>%
  group_by(Group) %>%
  identify_outliers(Score)
```

Values above Q3 + 1.5xIQR or below Q1 -1.5xIQR are considered as outliers.

Values above Q3 + 3xIQR or below Q1 -3xIQR are considered as extreme points (or extreme outliers).

However, one method is to create boxplots where you add points to your data. This allows you to get a better idea of the spread. Personally, I am a fan of **`geom_boxplot`**. I will show you below how this is done.


```{r, eval=TRUE, echo=FALSE, fig.cap="What could be occurring"}
#knitr::include_graphics("https://i.imgur.com/WJRGIBR.jpg")
knitr::include_graphics("images/summary-stats-hiding.jpg") # fig.asp = 1454/2362
```



```{r ass1b, cache=FALSE, echo=TRUE}
ggplot(data = df) + 
  aes(x = Group, y = Score) +
  geom_boxplot(outlier.size = 0, alpha = 0.3) + 
  geom_point(aes(color = ID),
             size = 6,
             position =position_jitterdodge(jitter.width = 0.1,
                                            jitter.height = 0,
                                            dodge.width = 0.75,
                                            seed = NA)) + 
  labs(title = "Scores for each Group shown as boxplots (with data points)") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5)) 

```

### Assumption \#2: Normality

The normality assumption can be checked by using one of the following two approaches:

1.  Analyzing the ANOVA model residuals to check the normality for all groups together. This approach is easier and it's very handy when you have many groups or if there are few data points per group.
2.  Check normality for each group separately. This approach might be used when you have only a few groups and many data points per group. In this section, we'll show you how to proceed for both option 1 and 2.

***Check normality assumption by analyzing the model residuals***. QQ plot and Shapiro-Wilk test of normality are used. QQ plot draws the correlation between a given data and the normal distribution.

```{r ass2, include=TRUE, cache=FALSE, echo=TRUE}
# Build the linear model
model <- aov(Score ~ Group, data=df)
# Create a QQ plot of residuals
ggqqplot(residuals(model))

# Compute Shapiro-Wilk test of normality
shapiro_test(residuals(model))

```

In the QQ plot, as all the points fall approximately along the reference line, we can assume normality. This conclusion is supported by the Shapiro-Wilk test. The p-value is not significant, so we can assume normality.

Check normality assumption by groups. Computing Shapiro-Wilk test for each group level. If the data is normally distributed, the p-value should be greater than 0.05.

```{r ass2b, include=TRUE, cache=FALSE, echo=TRUE}
df %>%
  group_by(Group) %>%
  shapiro_test(Score)
```

The score were normally distributed (p \> 0.05) for each group, as assessed by Shapiro-Wilk's test of normality.

Note that, if your sample size is greater than 50, the normal QQ plot is preferred because at larger sample sizes the Shapiro-Wilk test becomes very sensitive even to a minor deviation from normality.

QQ plot draws the correlation between a given data and the normal distribution. Create QQ plots for each group level:

```{r ass2c, include=TRUE, cache=FALSE, echo=TRUE}
ggqqplot(df, "Score", facet.by = "Group")
```

### Assumption \#3: Homogeneity of Variance

The assumption of homogeneity of variance is an assumption of the ANOVA stating that all comparison groups have the same variance.

Using Levene's test we can get a good idea if we have violated this. An alternative would be Bartlett's test (which we won't cover).

```{r ass3a, include=TRUE, cache=FALSE, echo=TRUE}

df %>% 
  levene_test(Score ~ Group)

```

From the output above, we can see that the p-value is \> 0.05, which is not significant. This means that, there is not a significant difference between variances across groups. Therefore, we can assume we have met the assumption of homogeneity of variances.

In a situation where the homogeneity of variance assumption is not met, you can compute the Welch one-way ANOVA test using the function `welch_anova_test()`. This test does not require the assumption of equal variances.

## Computing your model

Finally we can compute our model this will be the same as we did in our first workshop.

```{r, include=TRUE, cache=FALSE, echo=TRUE}
model <- aov(Score ~ Group, data=df)
model # print it in the console

model2 <- df %>% 
  anova_test(Score ~ Group)
model2 # print it in the console
```

### Understanding your model

```{r, include=TRUE, cache=FALSE, echo=TRUE}
effect_plot(model, pred = Group, interval = TRUE, plot.points = TRUE)
```

<!---BLOCK_LANDSCAPE_START--->
```{r, include=TRUE, cache=FALSE, echo=TRUE, fig.width=8, fig.asp=8.5/11}
performance::check_model(model) # will make some plots to check your model 
```
<!---BLOCK_LANDSCAPE_STOP--->


### Post-hoc tests

A significant one-way ANOVA is generally followed up by Tukey post-hoc tests to perform multiple pairwise comparisons between groups. Key R function: `tukey_hsd()`

```{r, include=TRUE, cache=FALSE, echo=TRUE}
pwc <- df %>% 
  tukey_hsd(Score ~ Group)
pwc
```

It can be seen from the output, that the TBI group differs from both the OI and Control groups (adjusted p-value = 0.004 and 0.005).

### Reporting your model

Using the `report` package

```{r, include=TRUE, cache=FALSE, echo=TRUE}
report(model)

#report_model(model)
#report_performance(model)
#report_statistics(model)
```

```{r, include=TRUE, cache=FALSE, echo=TRUE}
# Visualization: box plots with p-values
pwc <- pwc %>% add_xy_position(x = "Group")
ggboxplot(df, x = "Group", y = "Score") +
  stat_pvalue_manual(pwc, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(model2, detailed = TRUE),
    caption = get_pwc_label(pwc)
  )
```

A one-way ANOVA was performed to evaluate if the test scores was different for the 3 different treatment groups: Control (n = 10), OI (n = 10) and TBI (n = 10).

Values on test scores were statistically significantly different between different treatment groups, (F(2, 27) = 8.15, p = 0.002), partial omega squared = 0.32.

Post hoc comparisons using the Tukey HSD test indicated that the mean score in the TBI group (`r with(filter(df, Group == "TBI"), describe.mean.sd(Score, dtype="c"))`) was significantly lower than both the Control (`r with(filter(df, Group == "Control"), describe.mean.sd(Score, dtype="c"))`) and OI group (`r with(filter(df, Group == "OI"), describe.mean.sd(Score, dtype="c"))`). However, there was no significant difference between the OI and Control group.

# What's Next?

We redo what we just did but we start looking at interactions. If you feel uncomfortable with what we have done this week...things are about to get a whole lot worse for you. Review this as much as you can.


# Other Packages to look at?

[`effectsize`](https://easystats.github.io/see/articles/effectsize.html) package is part of the `easystats` group and provides some nice figures.

# Exercises

1. Change the dataset we used in this Module and run your own ANOVA!
2. Confirm the output makes sense.
